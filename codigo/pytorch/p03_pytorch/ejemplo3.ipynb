{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee4acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25008efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# --- Definir Transformaciones ---\n",
    "# 1. transforms.ToTensor(): Convierte la imagen (PIL) a un Tensor de PyTorch \n",
    "#    y escala los valores de los píxeles de [0, 255] a [0.0, 1.0].\n",
    "# 2. transforms.Normalize(): Normaliza el tensor. (0.5) es la media \n",
    "#    y (0.5) la desviación estándar que usaremos para centrar los datos.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# --- Descargar y Cargar Datos ---\n",
    "# PyTorch facilita esto inmensamente.\n",
    "# train=True descarga el set de entrenamiento.\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# --- Crear los DataLoaders ---\n",
    "# DataLoader es una herramienta increíblemente potente.\n",
    "# Maneja por nosotros:\n",
    "# 1. Batching: Agrupa los datos en \"lotes\" (ej. 64 imágenes a la vez).\n",
    "# 2. Shuffling: Mezcla los datos en cada epoch para mejorar el aprendizaje.\n",
    "# 3. Paralelismo: Carga los datos en hilos separados (num_workers).\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91630b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # --- Bloque Convolucional 1 ---\n",
    "        # Entrada: [1, 28, 28] (1 canal de color)\n",
    "        # Salida: [16, 28, 28] -> [16, 14, 14] (después de MaxPool)\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            # 1 canal de entrada, 16 \"filtros\" de salida, tamaño de filtro 3x3, padding=1 (para mantener el 28x28)\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Reduce el tamaño a la mitad (28x28 -> 14x14)\n",
    "        )\n",
    "        \n",
    "        # --- Bloque Convolucional 2 ---\n",
    "        # Entrada: [16, 14, 14]\n",
    "        # Salida: [32, 14, 14] -> [32, 7, 7] (después de MaxPool)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Reduce el tamaño a la mitad (14x14 -> 7x7)\n",
    "        )\n",
    "        \n",
    "        # --- Capa Completamente Conectada (Clasificador) ---\n",
    "        # Ahora \"aplanamos\" (flatten) la salida del bloque 2.\n",
    "        # Tamaño de salida: 32 canales * 7 alto * 7 ancho = 1568 características\n",
    "        # La entrada a la capa lineal DEBE ser 1568.\n",
    "        # Salida final: 10 neuronas (una para cada dígito: 0, 1, ..., 9)\n",
    "        self.fc_layer = nn.Linear(32 * 7 * 7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 1. Pasa por el primer bloque convolucional\n",
    "        x = self.conv_block1(x)\n",
    "        # 2. Pasa por el segundo bloque convolucional\n",
    "        x = self.conv_block2(x)\n",
    "        \n",
    "        # 3. \"Aplanar\" el tensor para la capa lineal\n",
    "        # Mantiene el tamaño del lote (-1) y aplana todo lo demás\n",
    "        x = x.view(-1, 32 * 7 * 7) \n",
    "        \n",
    "        # 4. Pasa por la capa clasificadora\n",
    "        x = self.fc_layer(x)\n",
    "        # NOTA: No aplicamos Softmax aquí porque la función de pérdida\n",
    "        # (CrossEntropyLoss) lo hace internamente por nosotros.\n",
    "        return x\n",
    "\n",
    "# Instanciamos el modelo\n",
    "model = CNN()\n",
    "\n",
    "# (Opcional) Mover el modelo a la GPU si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a72ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee08c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Lote [200/938], Loss: 0.1326\n",
      "Epoch [1/5], Lote [400/938], Loss: 0.1699\n",
      "Epoch [1/5], Lote [600/938], Loss: 0.0635\n",
      "Epoch [1/5], Lote [800/938], Loss: 0.0326\n",
      "Epoch [2/5], Lote [200/938], Loss: 0.0726\n",
      "Epoch [2/5], Lote [400/938], Loss: 0.0270\n",
      "Epoch [2/5], Lote [600/938], Loss: 0.0959\n",
      "Epoch [2/5], Lote [800/938], Loss: 0.0424\n",
      "Epoch [3/5], Lote [200/938], Loss: 0.0162\n",
      "Epoch [3/5], Lote [400/938], Loss: 0.0372\n",
      "Epoch [3/5], Lote [600/938], Loss: 0.0287\n",
      "Epoch [3/5], Lote [800/938], Loss: 0.0652\n",
      "Epoch [4/5], Lote [200/938], Loss: 0.0073\n",
      "Epoch [4/5], Lote [400/938], Loss: 0.0022\n",
      "Epoch [4/5], Lote [600/938], Loss: 0.0034\n",
      "Epoch [4/5], Lote [800/938], Loss: 0.0645\n",
      "Epoch [5/5], Lote [200/938], Loss: 0.1169\n",
      "Epoch [5/5], Lote [400/938], Loss: 0.0694\n",
      "Epoch [5/5], Lote [600/938], Loss: 0.0437\n",
      "Epoch [5/5], Lote [800/938], Loss: 0.0056\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5 # MNIST aprende rápido\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # 'train_loader' nos da lotes de (imágenes, etiquetas)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Mover los datos a la GPU (si la estamos usando)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 2. Calcular Loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # 3. Resetear gradientes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Backward pass (Autograd)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Actualizar pesos\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Lote [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9860657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación en el conjunto de Prueba ---\n",
      "Precisión en las 10,000 imágenes de prueba: 99.02%\n"
     ]
    }
   ],
   "source": [
    "# Poner el modelo en modo evaluación\n",
    "model.eval()\n",
    "\n",
    "# No necesitamos calcular gradientes durante la evaluación\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Hacemos la predicción\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # torch.max devuelve (valor_maximo, indice_maximo)\n",
    "        # Nos interesa el índice (la clase predicha)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'\\n--- Evaluación en el conjunto de Prueba ---')\n",
    "    print(f'Precisión en las 10,000 imágenes de prueba: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ecbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
